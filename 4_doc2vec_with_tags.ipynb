{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects.packages import importr\n",
    "# from rpy2.robjects import pandas2ri\n",
    "# pandas2ri.activate()\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read previously generated data with labels\n",
    "\n",
    "# df = pd.read_csv(\"~/imdb/data/df_tagged.csv\") \n",
    "df = pd.read_csv(\"/home/ruser/imdb/data/df_tagged_real_train.csv\")\n",
    "df['idx'] = range(0, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11354, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Transform to lower case\n",
    "corpus = df[\"text\"].str.lower()\n",
    "\n",
    "## Removing punctuation\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sentences = [tokenizer.tokenize(doc) for doc in corpus]\n",
    "\n",
    "# Stemming and Lemmatisation\n",
    "\n",
    "## stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "## lemmatisation\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "sentences = [[wordnet_lemmatizer.lemmatize(porter_stemmer.stem(token)) for token in sentence] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "docs = []\n",
    "docs = [gensim.models.doc2vec.TaggedDocument(words = sentences[texts], tags=[df['rating'].iloc[idx]]) \n",
    "        for texts, idx in enumerate(df['idx'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "docs = []\n",
    "docs = [gensim.models.doc2vec.TaggedDocument(words = sentences[text], tags=[df['rating'].iloc[idx]]) \n",
    "        for idx, text in enumerate(df['idx'].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ce81b4a8822e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# docs[1][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "len(docs)\n",
    "# docs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vector_size = 150\n",
    "window_size = 10\n",
    "min_count = 5\n",
    "sampling_threshold = 1e-5 # high-frequency words cutting\n",
    "negative_size = 10\n",
    "train_epoch = 1\n",
    "dm = 1 # 0 = dbow; 1 = dmpv\n",
    "dbow_words = 1 # train or not word embeeddings\n",
    "worker_count = 4 # number of parallel processes, no reproducibility \n",
    "\n",
    "model = gensim.models.Doc2Vec(size = vector_size, window = window_size, min_count = min_count, \n",
    "                              sample = sampling_threshold, workers = worker_count, \n",
    "                              dm = dm, dbow_words = 1,\n",
    "                              negative = negative_size, \n",
    "                              dm_concat = 1, \n",
    "                              iter = train_epoch, \n",
    "                              alpha = 0.025, min_alpha = 0.0025)\n",
    "\n",
    "model.build_vocab(docs)\n",
    "model.train(docs, \n",
    "            total_examples = len(docs), \n",
    "            epochs = model.iter)\n",
    "\n",
    "\n",
    "\n",
    "# model.train(it, \n",
    "#             total_examples = len(sentences), \n",
    "#             epochs = model.iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.Doc2Vec.load(\"~/imdb/models/doc2vec_tagged.bin\")\n",
    "model = gensim.models.Doc2Vec.load(\"/home/ubuntu/imdb/models/doc2vec_real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8.6, 0.991557240486145), (9.3, 0.9906759262084961), (7.6, 0.9900305271148682), (8.5, 0.9891781806945801), (8.0, 0.9891082644462585), (8.7, 0.9886906743049622), (8.9, 0.9880008697509766), (8.3, 0.9879062175750732), (8.1, 0.9765941500663757), (8.2, 0.8884684443473816)]\n"
     ]
    }
   ],
   "source": [
    "# to get most similar document with similarity scores using document-index\n",
    "similar_doc = model.docvecs.most_similar(2) \n",
    "print(similar_doc)\n",
    "# to get most similar document with similarity scores using document- name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.docvecs.indexed_doctags('9.3')\n",
    "model.docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sims = model.docvecs.most_similar('_horror_3')\n",
    "# print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Rating\n",
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14389"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14389, 150)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.docvecs\n",
    "# X = model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14389, 150)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.wv.syn0.shape\n",
    "# model.wv.index2word\n",
    "# model.docvecs.doctag_syn0.shape\n",
    "# model.docvecs.offset2doctag\n",
    "# model.docvecs.max_rawint\n",
    "# model.docvecs.doctags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# y = np.asarray([model.docvecs.offset2doctag[i].split('_')[2] for i in range(len(X))])\n",
    "# y = np.asarray([model.docvecs.offset2doctag[i] for i in range(len(X))])\n",
    "y = np.asarray([model.docvecs.offset2doctag[i] for i in range(len(X))])\n",
    "y = y.astype(int)\n",
    "\n",
    "lin = linear_model.LinearRegression(n_jobs = -1)\n",
    "lin.fit(X, y)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y, lin.predict(X)))\n",
    "\n",
    "## tags were generated artificially without counting for real movie rating (not yeat combined with scrapped data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.999999, 7.000001, 7.999999, 7.999999, 7.999999, 8.      ,\n",
       "       7.999999, 7.999999, 7.      , 8.      , 8.      , 8.999999],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"Mean squared error: %.2f\"\n",
    "#       % mean_squared_error(y, lin.predict(X)))\n",
    "\n",
    "lin.predict(X)[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = \"Amazing!!!\"\n",
    "# infered = model.infer_vector(a).reshape(1,-1)\n",
    "# preds = lin.predict(infered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/home/ruser/imdb/data/df_tagged_real_test.csv\")\n",
    "df_test['idx'] = range(0, df_test.shape[0])\n",
    "\n",
    "corpus = df_test[\"text\"].str.lower()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sentences = [tokenizer.tokenize(doc) for doc in corpus]\n",
    "porter_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "sentences = [[wordnet_lemmatizer.lemmatize(porter_stemmer.stem(token)) for token in sentence] for sentence in sentences]\n",
    "\n",
    "\n",
    "docs_test = []\n",
    "docs_test = [gensim.models.doc2vec.TaggedDocument(words = sentences[text], tags=[df_test['rating'].iloc[idx]]) \n",
    "        for idx, text in enumerate(df_test['idx'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(columns = ['infered', 'predicted', 'rating'])\n",
    "\n",
    "for i in range(0, len(docs_test)):\n",
    "# i = 0\n",
    "\n",
    "    d = {'infered': model.infer_vector(docs_test[i][0]).reshape(1,-1).tolist(), \n",
    "         'predicted': lin.predict(model.infer_vector(docs_test[i][0]).reshape(1,-1)).tolist(), \n",
    "         'rating': docs_test[i][1]}\n",
    "    # pd.DataFrame(data = d)\n",
    "\n",
    "    preds = pd.concat([preds, pd.DataFrame(data = d)], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds.to_csv('/home/ruser/imdb/data/test_scrapped.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
